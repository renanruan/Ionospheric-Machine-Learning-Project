{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1O5lqwGG4gz6"
      },
      "outputs": [],
      "source": [
        "# FAZENDO IMPORTS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score, confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  CARREGANDO BASE DE DADOS\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "#data = pd.read_csv('/content/drive/MyDrive/Machine Learning Project/Regression/Final_Grads_SJCU.csv')\n",
        "\n",
        "#feature_data = data.iloc[:, :3]\n",
        "#target_data = data.iloc[:, -1]\n",
        "\n",
        "#feature_tensor = torch.FloatTensor(feature_data.values)\n",
        "#target_tensor = torch.FloatTensor(target_data.values).view(-1, 1)  # Ensure target_tensor is a 2D tensor with shape (N, 1)\n",
        "\n",
        "#print(\"Feature tensor shape:\", feature_tensor.shape)\n",
        "#print(\"Target tensor shape:\", target_tensor.shape)"
      ],
      "metadata": {
        "id": "QqYOK6k743bM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   CONTROLE DE ALEATORIEDADE\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "id": "ZUgPYzkUqRfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ae1605-1ad0-493f-bf3c-589657676978"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7df2e6fc1210>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  GERANDO UM MOCK DATASET\n",
        "# ok\n",
        "\n",
        "num_samples=100\n",
        "\n",
        "# Generate random features (float normalized between 0 and 1)\n",
        "features = np.random.rand(num_samples, 3)\n",
        "\n",
        "# Calculate the binary classification based on the last values of the features\n",
        "HANS = np.zeros(num_samples)\n",
        "for i in range(num_samples):\n",
        "    # Example binary classification rule: if the sum of the last two values of feature1 is greater than 1, classify as 1, else 0\n",
        "    HANS[i] = 400 * (features[i, 0] + features[i-1, 0] - features[i, 1] - features[i-1, 1] + features[i, 2] + features[i-1, 2])\n",
        "\n",
        "# Create DataFrame\n",
        "data = pd.DataFrame(features, columns=['feature1', 'feature2', 'feature3'])\n",
        "# Add binary classification column\n",
        "target = pd.DataFrame(HANS, columns=['target'])\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "features_tensor = torch.FloatTensor(data.values)\n",
        "target_tensor = torch.FloatTensor(target.values).view(-1, 1)\n",
        "\n",
        "print(data)\n",
        "print(target)\n",
        "print(features_tensor.shape)\n",
        "print(target_tensor.shape)"
      ],
      "metadata": {
        "id": "ptp_QDWzNBgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac0c9d8-0623-4abf-a596-2d21dc9a1e78"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    feature1  feature2  feature3\n",
            "0   0.374540  0.950714  0.731994\n",
            "1   0.598658  0.156019  0.155995\n",
            "2   0.058084  0.866176  0.601115\n",
            "3   0.708073  0.020584  0.969910\n",
            "4   0.832443  0.212339  0.181825\n",
            "..       ...       ...       ...\n",
            "95  0.035942  0.465598  0.542645\n",
            "96  0.286541  0.590833  0.030500\n",
            "97  0.037348  0.822601  0.360191\n",
            "98  0.127061  0.522243  0.769994\n",
            "99  0.215821  0.622890  0.085347\n",
            "\n",
            "[100 rows x 3 columns]\n",
            "        target\n",
            "0   -66.360892\n",
            "1   301.781647\n",
            "2   156.662737\n",
            "3   580.168166\n",
            "4   983.730573\n",
            "..         ...\n",
            "95  389.148018\n",
            "96  -64.321147\n",
            "97 -279.541396\n",
            "98  -20.100370\n",
            "99   21.235529\n",
            "\n",
            "[100 rows x 1 columns]\n",
            "torch.Size([100, 3])\n",
            "torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  SEPARAÇÃO DOS DADOS\n",
        "\n",
        "#data.head()\n",
        "\n",
        "#data_features = data.drop('HANS', axis=1)\n",
        "#data_target = data['HANS']\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(data_features, data_target, test_size=0.2, random_state=seed)\n",
        "\n",
        "#print(f\"Number of samples: {X_train.shape[0]}\")"
      ],
      "metadata": {
        "id": "dpdpq-w2qWp_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   CLASSES\n",
        "\n",
        "# Define the PyTorch linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Custom weighted MSE loss function\n",
        "class WeightedMSELoss(nn.Module):\n",
        "    def __init__(self, threshold=400, high_weight=5, low_weight=1):\n",
        "        super(WeightedMSELoss, self).__init__()\n",
        "        self.threshold = threshold\n",
        "        self.high_weight = high_weight\n",
        "        self.low_weight = low_weight\n",
        "\n",
        "    def forward(self, y_true, y_pred):\n",
        "        weights = torch.where(y_true > self.threshold, self.high_weight, self.low_weight)\n",
        "        return torch.mean(weights * (y_true - y_pred) ** 2)"
      ],
      "metadata": {
        "id": "uNYnC4yF2-mT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   GERAR MATRIX DE CONFUSÃO\n",
        "\n",
        "def apply_rule(y_test, y_pred):\n",
        "    new_test = np.where(y_test > 400, 1, 0)\n",
        "    new_preds = np.where(y_pred > 400, 1, 0)\n",
        "    return new_test, new_preds"
      ],
      "metadata": {
        "id": "IKBR90Bg41Kr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   TREINAMENTO - PREDIÇÃO - MÉTRICAS\n",
        "#   Utilizando um 5 fold com tamanho de treinamento 80% e teste 20% com uma função de custo Mean Square Error\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "# Initialize lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for train_index, test_index in kf.split(data):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train = features_tensor[train_index]\n",
        "    y_train = target_tensor[train_index]\n",
        "    X_test = features_tensor[test_index]\n",
        "    y_test = target_tensor[test_index]\n",
        "\n",
        "    # Initialize the model, loss function, and optimizer\n",
        "    model = LinearRegressionModel(input_dim=3, output_dim=1)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(y_train, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test)\n",
        "\n",
        "    new_test, new_preds = apply_rule(y_test, y_pred)\n",
        "\n",
        "    # Store the true and predicted values\n",
        "    true_labels.extend(new_test)\n",
        "    predicted_labels.extend(new_preds)\n",
        "\n",
        "    # Print the confusion matrix for each fold\n",
        "    print(f\"Confusion Matrix Fold {len(true_labels)}:\")\n",
        "    print(confusion_matrix(new_test, new_preds))\n",
        "    print(\" \")\n",
        "\n",
        "# Calculate the accuracy\n",
        "print('Accuracy:')\n",
        "print(accuracy_score(true_labels, predicted_labels))\n",
        "\n",
        "# Generate a classification report\n",
        "print('Classification Report:')\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "# Print the cross-validation confusion matrix\n",
        "print(\"Confusion Matrix Total:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joj7Yz-Et4MD",
        "outputId": "e56601bf-5268-42e9-c619-138911d0205b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 156912.1875\n",
            "Epoch 20/100, Loss: 117799.015625\n",
            "Epoch 30/100, Loss: 97705.3046875\n",
            "Epoch 40/100, Loss: 87044.109375\n",
            "Epoch 50/100, Loss: 81073.109375\n",
            "Epoch 60/100, Loss: 77446.0859375\n",
            "Epoch 70/100, Loss: 75001.796875\n",
            "Epoch 80/100, Loss: 73165.1015625\n",
            "Epoch 90/100, Loss: 71650.75\n",
            "Epoch 100/100, Loss: 70316.8984375\n",
            "Confusion Matrix Fold 20:\n",
            "[[8 3]\n",
            " [5 4]]\n",
            " \n",
            "Epoch 10/100, Loss: 155419.625\n",
            "Epoch 20/100, Loss: 116714.5625\n",
            "Epoch 30/100, Loss: 96868.796875\n",
            "Epoch 40/100, Loss: 86352.375\n",
            "Epoch 50/100, Loss: 80463.9765625\n",
            "Epoch 60/100, Loss: 76883.796875\n",
            "Epoch 70/100, Loss: 74466.7734375\n",
            "Epoch 80/100, Loss: 72647.21875\n",
            "Epoch 90/100, Loss: 71145.2421875\n",
            "Epoch 100/100, Loss: 69821.96875\n",
            "Confusion Matrix Fold 40:\n",
            "[[8 0]\n",
            " [6 6]]\n",
            " \n",
            "Epoch 10/100, Loss: 142833.96875\n",
            "Epoch 20/100, Loss: 108464.3125\n",
            "Epoch 30/100, Loss: 91249.6875\n",
            "Epoch 40/100, Loss: 82307.96875\n",
            "Epoch 50/100, Loss: 77367.1015625\n",
            "Epoch 60/100, Loss: 74371.9921875\n",
            "Epoch 70/100, Loss: 72333.65625\n",
            "Epoch 80/100, Loss: 70775.7734375\n",
            "Epoch 90/100, Loss: 69468.609375\n",
            "Epoch 100/100, Loss: 68300.984375\n",
            "Confusion Matrix Fold 60:\n",
            "[[ 7  1]\n",
            " [10  2]]\n",
            " \n",
            "Epoch 10/100, Loss: 153175.59375\n",
            "Epoch 20/100, Loss: 109999.2265625\n",
            "Epoch 30/100, Loss: 89039.703125\n",
            "Epoch 40/100, Loss: 78587.6484375\n",
            "Epoch 50/100, Loss: 73114.453125\n",
            "Epoch 60/100, Loss: 70009.5078125\n",
            "Epoch 70/100, Loss: 68039.703125\n",
            "Epoch 80/100, Loss: 66622.359375\n",
            "Epoch 90/100, Loss: 65481.8046875\n",
            "Epoch 100/100, Loss: 64487.3984375\n",
            "Confusion Matrix Fold 80:\n",
            "[[12  2]\n",
            " [ 5  1]]\n",
            " \n",
            "Epoch 10/100, Loss: 147374.484375\n",
            "Epoch 20/100, Loss: 110951.1640625\n",
            "Epoch 30/100, Loss: 92557.0390625\n",
            "Epoch 40/100, Loss: 82978.6171875\n",
            "Epoch 50/100, Loss: 77719.953125\n",
            "Epoch 60/100, Loss: 74586.953125\n",
            "Epoch 70/100, Loss: 72508.5078125\n",
            "Epoch 80/100, Loss: 70961.5234375\n",
            "Epoch 90/100, Loss: 69690.2109375\n",
            "Epoch 100/100, Loss: 68569.265625\n",
            "Confusion Matrix Fold 100:\n",
            "[[11  0]\n",
            " [ 5  4]]\n",
            " \n",
            "Accuracy:\n",
            "0.63\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.88      0.71        52\n",
            "           1       0.74      0.35      0.48        48\n",
            "\n",
            "    accuracy                           0.63       100\n",
            "   macro avg       0.67      0.62      0.60       100\n",
            "weighted avg       0.67      0.63      0.60       100\n",
            "\n",
            "Confusion Matrix Total:\n",
            "[[46  6]\n",
            " [31 17]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   TREINAMENTO - PREDIÇÃO - MÉTRICAS\n",
        "#   Utilizando um 5 fold com tamanho de treinamento 80% e teste 20% com uma função de custo priorizando valores maiores que 400\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "# Initialize lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "for train_index, test_index in kf.split(data):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train = features_tensor[train_index]\n",
        "    y_train = target_tensor[train_index]\n",
        "    X_test = features_tensor[test_index]\n",
        "    y_test = target_tensor[test_index]\n",
        "\n",
        "    # Initialize the model, loss function, and optimizer\n",
        "    model = LinearRegressionModel(input_dim=3, output_dim=1)\n",
        "    criterion = WeightedMSELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(y_train, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test)\n",
        "\n",
        "    new_test, new_preds = apply_rule(y_test, y_pred)\n",
        "\n",
        "    # Store the true and predicted values\n",
        "    true_labels.extend(new_test)\n",
        "    predicted_labels.extend(new_preds)\n",
        "\n",
        "    # Print the confusion matrix for each fold\n",
        "    print(f\"Confusion Matrix Fold {len(true_labels)}:\")\n",
        "    print(confusion_matrix(new_test, new_preds))\n",
        "    print(\" \")\n",
        "\n",
        "# Calculate the accuracy\n",
        "print('Accuracy:')\n",
        "print(accuracy_score(true_labels, predicted_labels))\n",
        "\n",
        "# Generate a classification report\n",
        "print('Classification Report:')\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "\n",
        "# Print the cross-validation confusion matrix\n",
        "print(\"Confusion Matrix Total:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HNCsJy43lxz",
        "outputId": "003149ba-7cb2-4e5f-9fc6-59693a6500c0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 268358.21875\n",
            "Epoch 20/100, Loss: 160968.375\n",
            "Epoch 30/100, Loss: 144801.03125\n",
            "Epoch 40/100, Loss: 138566.5\n",
            "Epoch 50/100, Loss: 133739.828125\n",
            "Epoch 60/100, Loss: 129398.546875\n",
            "Epoch 70/100, Loss: 125417.078125\n",
            "Epoch 80/100, Loss: 121755.6875\n",
            "Epoch 90/100, Loss: 118385.953125\n",
            "Epoch 100/100, Loss: 115282.9140625\n",
            "Confusion Matrix Fold 20:\n",
            "[[ 1 10]\n",
            " [ 0  9]]\n",
            " \n",
            "Epoch 10/100, Loss: 281622.3125\n",
            "Epoch 20/100, Loss: 163905.859375\n",
            "Epoch 30/100, Loss: 144941.6875\n",
            "Epoch 40/100, Loss: 138573.578125\n",
            "Epoch 50/100, Loss: 134080.484375\n",
            "Epoch 60/100, Loss: 130106.734375\n",
            "Epoch 70/100, Loss: 126461.203125\n",
            "Epoch 80/100, Loss: 123099.078125\n",
            "Epoch 90/100, Loss: 119995.5234375\n",
            "Epoch 100/100, Loss: 117129.671875\n",
            "Confusion Matrix Fold 40:\n",
            "[[ 1  7]\n",
            " [ 0 12]]\n",
            " \n",
            "Epoch 10/100, Loss: 265193.8125\n",
            "Epoch 20/100, Loss: 167303.53125\n",
            "Epoch 30/100, Loss: 151311.109375\n",
            "Epoch 40/100, Loss: 144797.5\n",
            "Epoch 50/100, Loss: 139702.625\n",
            "Epoch 60/100, Loss: 135103.5\n",
            "Epoch 70/100, Loss: 130870.703125\n",
            "Epoch 80/100, Loss: 126965.0234375\n",
            "Epoch 90/100, Loss: 123359.2109375\n",
            "Epoch 100/100, Loss: 120029.296875\n",
            "Confusion Matrix Fold 60:\n",
            "[[ 6  2]\n",
            " [ 1 11]]\n",
            " \n",
            "Epoch 10/100, Loss: 249536.0\n",
            "Epoch 20/100, Loss: 155412.15625\n",
            "Epoch 30/100, Loss: 143280.90625\n",
            "Epoch 40/100, Loss: 138289.421875\n",
            "Epoch 50/100, Loss: 134219.953125\n",
            "Epoch 60/100, Loss: 130529.8984375\n",
            "Epoch 70/100, Loss: 127148.1875\n",
            "Epoch 80/100, Loss: 124045.0390625\n",
            "Epoch 90/100, Loss: 121196.265625\n",
            "Epoch 100/100, Loss: 118579.953125\n",
            "Confusion Matrix Fold 80:\n",
            "[[5 9]\n",
            " [0 6]]\n",
            " \n",
            "Epoch 10/100, Loss: 262046.421875\n",
            "Epoch 20/100, Loss: 164372.5\n",
            "Epoch 30/100, Loss: 149816.34375\n",
            "Epoch 40/100, Loss: 144197.59375\n",
            "Epoch 50/100, Loss: 139810.609375\n",
            "Epoch 60/100, Loss: 135833.671875\n",
            "Epoch 70/100, Loss: 132159.578125\n",
            "Epoch 80/100, Loss: 128756.984375\n",
            "Epoch 90/100, Loss: 125603.953125\n",
            "Epoch 100/100, Loss: 122681.0625\n",
            "Confusion Matrix Fold 100:\n",
            "[[4 7]\n",
            " [0 9]]\n",
            " \n",
            "Accuracy:\n",
            "0.64\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.33      0.49        52\n",
            "           1       0.57      0.98      0.72        48\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.76      0.65      0.60       100\n",
            "weighted avg       0.77      0.64      0.60       100\n",
            "\n",
            "Confusion Matrix Total:\n",
            "[[17 35]\n",
            " [ 1 47]]\n"
          ]
        }
      ]
    }
  ]
}